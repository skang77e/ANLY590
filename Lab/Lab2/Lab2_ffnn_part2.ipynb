{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab2_ffnn_part2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f50ODjhO9CSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7e0w-139Iij",
        "colab_type": "text"
      },
      "source": [
        "### 1. Activation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsmLzjE9s-a",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Let's start by writing some functions for activation functions that we would like to be able to use.\n",
        "\n",
        "Fill in the functions below to implement the associated activation functions. Any time you need a special function (e.g. exponentation), try to find a version in NumPy so that your activation functions will work on single values as well as arrays.\n",
        "\n",
        "*bonus*: try to implment the ReLU activation function so that it works elementwise on a NumPy -- this is called \"vectorizing\" your code. Hint: check out the `np.where` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr4mkpLh9yGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear(z):\n",
        "  '''\n",
        "  linear activation function\n",
        "  '''\n",
        "  return z\n",
        "\n",
        "# more specifically, the logistic sigmoid that has values between 0 and 1\n",
        "def sigmoid(z):\n",
        "  '''\n",
        "  sigmoid activation function\n",
        "  '''\n",
        "  return 1/(1 + np.exp(-z)) \n",
        "\n",
        "def tanh(z):\n",
        "  '''\n",
        "  tanh activation function\n",
        "  '''\n",
        "  return np.tanh(z)\n",
        "\n",
        "def relu(z):\n",
        "  # if z < 0:\n",
        "  #   return 0\n",
        "  # else \n",
        "  #   return z\n",
        "  # return np.where(z>0, z, 0)\n",
        "  return np.maximum(0,z)â€©"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VEZ_W1V7yUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.array([-1.0, 0.0, 1.0])\n",
        "\n",
        "np.testing.assert_equal(linear(5), 5)\n",
        "np.testing.assert_equal(linear(-3.0), -3.0)\n",
        "np.testing.assert_array_equal(linear(a), a)\n",
        "\n",
        "np.testing.assert_equal(sigmoid(0.0), 0.5)\n",
        "np.testing.assert_allclose(sigmoid(a), [0.26894142, 0.5, 0.73105858])\n",
        "\n",
        "np.testing.assert_equal(tanh(0.0), 0.0)\n",
        "np.testing.assert_allclose(tanh(a), [-0.76159416, 0.0, 0.76159416])\n",
        "\n",
        "np.testing.assert_equal(relu(5), 5)\n",
        "np.testing.assert_equal(relu(-5), 0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3R7FZ8y9S1v",
        "colab_type": "text"
      },
      "source": [
        "### 2. Try it out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edvxHceU_XkJ",
        "colab_type": "text"
      },
      "source": [
        "Let's reuse our neural net layer function from last time.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbMrGPe9_X2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nn_layer(X, W, b, f):\n",
        "  return f(np.dot(X, W) + b)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLIsi2EuAkut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nn_two_layers(X, W_1, b_1, f_1, W_2, b_2, f_2):\n",
        "  H = nn_layer(X, W_1, b_1, f_1)\n",
        "  Y_hat = nn_layer(H, W_2, b_2, f_2)\n",
        "  return Y_hat"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf7oiWBp_jbE",
        "colab_type": "text"
      },
      "source": [
        "But now, we have multiple activation functions to try out. As we did previously, create randomized weight matrices for a network with scalar input, scalar output and any number of hidden nodes in a single layer. Generate plots of this input output relationships.\n",
        "\n",
        "This time, try out different activation functions: linear, sigmoid, tanh, relu and visualize the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er92ByXX_egf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the input dimension, the number of hidden units, and the number of ouptput units\n",
        "n_input, n_hidden, n_output = 1, 500, 1\n",
        "\n",
        "# We want get the NN's output for a range of input values, so that we cant plot\n",
        "# input vs output. We can get evenly space values using `np.linspace`. We also\n",
        "# want to process these inputs as a \"batch\", so we use `np.newaxis` to turn this\n",
        "# 1-d array into a 2-d array with a single column.\n",
        "n_grid = 100\n",
        "X = np.linspace(-10, 10, n_grid)[:, np.newaxis]\n",
        "\n",
        "# We can generate random values (drawn from a standard gaussian distribution --\n",
        "# mean = 0, standard deviation = 1), with `np.random.randn(shape)`\n",
        "W_1 = np.random.randn(n_input, n_hidden)\n",
        "b_1 = np.random.randn(n_hidden)\n",
        "W_2 = np.random.randn(n_hidden, n_output)\n",
        "b_2 = np.random.randn(n_output)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we1S7m9GOgo8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "af709558-8129-4e48-c1ff-2008cc31222c"
      },
      "source": [
        "Y_hat = nn_two_layers(X, W_1, b_1, sigmoid, W_2, b_2, linear)\n",
        "plt.plot(X, Y_hat)\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBI23a_F9Xuu",
        "colab_type": "text"
      },
      "source": [
        "### 3.  Outputs and Losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgPrHIxbBEVy",
        "colab_type": "text"
      },
      "source": [
        "Next, we'll define some common Output activation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQxHU6t3PraV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(z):\n",
        "  '''\n",
        "  sigmoid output function\n",
        "  '''\n",
        "  return 1/(1 + np.exp(-z)) \n",
        "\n",
        "def softmax(z):\n",
        "  '''\n",
        "  softmax output function\n",
        "  '''\n",
        "  row_sums = (np.exp(z).sum(axis=1))[:,np.newaxis]\n",
        "  return np.exp(z) / row_sums"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAFko6cqRFP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.testing.assert_almost_equal(\n",
        "    sigmoid(2),\n",
        "    np.array([.88]),\n",
        "    decimal=2\n",
        ")\n",
        "\n",
        "np.testing.assert_almost_equal(\n",
        "    sigmoid(np.array([2,-2,1,-1])),\n",
        "    np.array([.88, .12, .73, .27]),\n",
        "    decimal=2\n",
        ")\n",
        "\n",
        "np.testing.assert_almost_equal(\n",
        "    softmax(np.array([[2,5,1], [3,1,1]])),\n",
        "    np.array([[0.046, 0.93, 0.017],\n",
        "       [0.78, 0.10, 0.10]]),\n",
        "    decimal=2\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNrgYJtqBKyw",
        "colab_type": "text"
      },
      "source": [
        "Next, we'll define some common Loss functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMvoYMgSBNiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def squared_error(y_hat, y_true):\n",
        "  '''\n",
        "  squared error loss\n",
        "  '''\n",
        "  return ((y_hat - y_true)**2)\n",
        "\n",
        "\n",
        "def binary_crossentropy(y_hat, y_true):\n",
        "  '''\n",
        "  binary crossentropy loss for label-encoded inputs\n",
        "  '''\n",
        "  return - y_true*np.log(y_hat) - (1-y_true)*np.log(1 - y_hat)\n",
        "\n",
        "\n",
        "def binary_crossentropy_onehot(y_hat, y_true):\n",
        "  '''\n",
        "  binary crossentropy loss for onehot-encoded inputs\n",
        "  '''\n",
        "  return - (y_true * np.log(y_hat)).sum(axis=1)\n",
        "\n",
        "\n",
        "def categorical_crossentropy(y_hat, y_true):\n",
        "  '''\n",
        "  categorical crossentropy loss for onehot-encoded inputs\n",
        "  '''\n",
        "  return - (y_true * np.log(y_hat)).sum(axis=1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgAP3aFeEWOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.testing.assert_equal(\n",
        "    squared_error(np.array([1,2,4]), np.array([5,4,3])),\n",
        "    np.array([16, 4, 1])\n",
        ")\n",
        "\n",
        "\n",
        "np.testing.assert_almost_equal(\n",
        "    binary_crossentropy(\n",
        "        np.array([.51, .49, .99, 0.01, .99 ]), \n",
        "        np.array([1, 1, 1, 1, 0])),\n",
        "    np.array([0.67, 0.71, 0.01, 4.60, 4.60]),\n",
        "    decimal=2\n",
        ")\n",
        "\n",
        "np.testing.assert_almost_equal(\n",
        "    binary_crossentropy_onehot(\n",
        "        np.array([[.49, .51], [.51, .49], [.01, .99], [0.99, .01], [.01, .99] ]), \n",
        "        np.array([[0, 1], [0, 1], [0, 1], [0, 1], [1, 0]])),\n",
        "    np.array([0.67, 0.71, 0.01, 4.60, 4.60]),\n",
        "    decimal=2\n",
        ")\n",
        "\n",
        "np.testing.assert_almost_equal(\n",
        "      categorical_crossentropy(\n",
        "        np.array([[.4, .5, .1], [.2, .2, .6]  ]), \n",
        "        np.array([[0, 1, 0], [0, 1, 0],])),\n",
        "    np.array([0.69, 1.6]),\n",
        "    decimal=2\n",
        ")\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8FZ8gj-9dkd",
        "colab_type": "text"
      },
      "source": [
        "###4. Discussion problem with your groups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCdSFuKmTk7v",
        "colab_type": "text"
      },
      "source": [
        "Suppose we want to predict if a person is a credit risk (Yes or No) based on their {Income, Age, YearsOfEducation}. Draw a diagram of a possible neural network (with one hidden layer) to fit a datset like this. \n",
        "* How many input nodes and output nodes are there?\n",
        "* Pick how many nodes are in the hidden layer. Pick an activation function in the hidden layer. Include bias nodes at the hidden layer and the output layer.\n",
        "* What activation function would you pick for the output layer?\n",
        "* What loss function would you pick for fitting this model?\n",
        "* How many total free parameters are in this network? \n",
        "* Write an equation for the output of this network as a function of its input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSMMIuAD47PN",
        "colab_type": "text"
      },
      "source": [
        "- How many input nodes and output nodes are there?\n",
        "  - 3 input nodes and 2 output node\n",
        "- Pick how many nodes are in the hidden layer. Pick an activation function in the hidden layer. Include bias nodes at the hidden layer and the output layer.\n",
        "  - 4 nodes in hidden layer (3 + 1 bias), I would pick ReLU for activation function \n",
        "- What activation function would you pick for the output layer?\n",
        "  - I would pick Sigmoid for output activation function\n",
        "- What loss function would you pick for fitting this model?\n",
        "  - I would pick binary cross entropy loss for loss function\n",
        "- How many total free parameters are in this network?\n",
        "  - I have 6 total free parameters in this network\n",
        "- Write an equation for the output of this network as a function of its input.  \n",
        "  - y = 1/(1+exp(-max(0,x))"
      ]
    }
  ]
}